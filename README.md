# OPONeRF: One-Point-One NeRF for Robust Neural Rendering

## TODO List
- [x] Dataset Release
  - [x] Cooking-Perturbation Dataset
  - [x] MeetRoom-Perturbation Dataset
  - [x] Spatial Reconstruction Dataset Links
  - [x] Spatio-temporal Reconstruction Dataset Links
- [ ] Code Release
  - [ ] Training Code
  - [ ] Inference Code

## Dataset

### Static Scene Datasets
* **Cooking-Perturbation Dataset** ([Download](https://cloud.tsinghua.edu.cn/d/90ef1341cd0c4cfebb37/))
  - Re-organized from N3DV dataset
  - Camera poses estimated using COLMAP

* **MeetRoom-Perturbation Dataset** ([Download](https://cloud.tsinghua.edu.cn/d/fa1bc48c5bfd4c62a87f/))
  - Re-organized from MeetRoom dataset
  - Camera poses estimated using COLMAP

### Generalization Datasets 
* **Generalizable Spatial Reconstruction**
  - Available via [IBRNet](https://github.com/googleinterns/IBRNet) or [NeuRay](https://github.com/liuyuan-pal/NeuRay)

* **Generalizable Spatio-temporal Reconstruction**
  - Available via [MonoNeRF](https://github.com/tianfr/MonoNeRF)


## Citation
If you find our work useful in your research, please consider citing:
```
@article{zheng2024oponerf,
  title={OPONeRF: One-Point-One NeRF for Robust Neural Rendering},
  author={Zheng, Yu and Duan, Yueqi and Zheng, Kangfu and Yan, Hongru and Lu, Jiwen and Zhou, Jie},
  journal={arXiv preprint arXiv:2409.20043},
  year={2024}
}
```

## Contact
For any questions, please open an issue in this repository or contact yu-zheng AT tsinghua.edu.cn.
